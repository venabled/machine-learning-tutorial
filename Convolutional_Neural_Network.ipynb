{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Convolutional Neural Network.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/venabled/machine-learning-tutorial/blob/master/Convolutional_Neural_Network.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "2jpxDFHhPbNm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten, BatchNormalization, Conv2D\n",
        "from keras.layers import MaxPool2D, GlobalAveragePooling2D\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import keras.utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o7I8vacfPh0K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a671e6b5-0a3e-45d5-ae13-f11200a30f29"
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype(np.float32)\n",
        "x_test = x_test.astype(np.float32)\n",
        "x_train -= 128.0\n",
        "x_test -= 128.0\n",
        "y_train = keras.utils.to_categorical(y_train)\n",
        "y_test = keras.utils.to_categorical(y_test)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 33s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CGSJbb3ZSS7e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "e43596e3-5216-498f-ff22-04c1b1c0bef2"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Each of the convolutional blocks include a 3x3 kernel, relu, L2 regularization\n",
        "# and a batch normalization layer\n",
        "model.add(Conv2D(32, kernel_size=3, padding='same', input_shape=(32,32,3), kernel_regularizer=l2(0.002)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=3, padding='same', kernel_regularizer=l2(0.002)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=3, padding='same', kernel_regularizer=l2(0.002)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "# Add in some pooling to downsample by a factor of 2. After this downsample we\n",
        "# will do more convolutions, but double the number of filters, keeping the total\n",
        "# computation the same.\n",
        "model.add(MaxPool2D())\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=3, padding='same', kernel_regularizer=l2(0.002)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=3, padding='same', kernel_regularizer=l2(0.002)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=3, padding='same', kernel_regularizer=l2(0.002)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Actually build the model\n",
        "model.compile(optimizer='nadam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_26 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_27 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_28 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_29 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_30 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_31 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_32 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                650       \n",
            "_________________________________________________________________\n",
            "activation_33 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 113,546\n",
            "Trainable params: 112,970\n",
            "Non-trainable params: 576\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "09NSxlnBT8K5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37866cd2-4c08-4ba3-e2a7-6dbf21a2b695"
      },
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "K.get_value(model.optimizer.lr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00020000001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "eRwC-zOWIANa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3125
        },
        "outputId": "3d32d27e-a537-4b5c-d5a8-9e6e33d12dfb"
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=25,\n",
        "                    batch_size=64,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    verbose=1, \n",
        "                    callbacks=[ReduceLROnPlateau(patience=5)])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "50000/50000 [==============================] - 54s 1ms/step - loss: 1.4898 - acc: 0.5697 - val_loss: 1.4665 - val_acc: 0.5678\n",
            "Epoch 2/100\n",
            "50000/50000 [==============================] - 37s 744us/step - loss: 1.1292 - acc: 0.6895 - val_loss: 1.6592 - val_acc: 0.5562\n",
            "Epoch 3/100\n",
            "50000/50000 [==============================] - 37s 747us/step - loss: 1.0449 - acc: 0.7286 - val_loss: 1.1844 - val_acc: 0.6793\n",
            "Epoch 4/100\n",
            "50000/50000 [==============================] - 37s 747us/step - loss: 0.9990 - acc: 0.7491 - val_loss: 1.3731 - val_acc: 0.6460\n",
            "Epoch 5/100\n",
            "50000/50000 [==============================] - 37s 747us/step - loss: 0.9692 - acc: 0.7612 - val_loss: 1.5221 - val_acc: 0.6051\n",
            "Epoch 6/100\n",
            "50000/50000 [==============================] - 37s 741us/step - loss: 0.9501 - acc: 0.7687 - val_loss: 2.4149 - val_acc: 0.4977\n",
            "Epoch 7/100\n",
            "50000/50000 [==============================] - 37s 744us/step - loss: 0.9285 - acc: 0.7789 - val_loss: 1.1976 - val_acc: 0.6985\n",
            "Epoch 8/100\n",
            "50000/50000 [==============================] - 37s 742us/step - loss: 0.9149 - acc: 0.7834 - val_loss: 1.6215 - val_acc: 0.6303\n",
            "Epoch 9/100\n",
            "50000/50000 [==============================] - 36s 728us/step - loss: 0.7142 - acc: 0.8477 - val_loss: 0.7269 - val_acc: 0.8358\n",
            "Epoch 10/100\n",
            "50000/50000 [==============================] - 37s 743us/step - loss: 0.6148 - acc: 0.8665 - val_loss: 0.6879 - val_acc: 0.8382\n",
            "Epoch 11/100\n",
            "50000/50000 [==============================] - 37s 745us/step - loss: 0.5587 - acc: 0.8787 - val_loss: 0.6771 - val_acc: 0.8317\n",
            "Epoch 12/100\n",
            "50000/50000 [==============================] - 37s 743us/step - loss: 0.5158 - acc: 0.8874 - val_loss: 0.6851 - val_acc: 0.8268\n",
            "Epoch 13/100\n",
            "50000/50000 [==============================] - 37s 742us/step - loss: 0.4793 - acc: 0.8959 - val_loss: 0.6533 - val_acc: 0.8333\n",
            "Epoch 14/100\n",
            "50000/50000 [==============================] - 37s 740us/step - loss: 0.4525 - acc: 0.9013 - val_loss: 0.6428 - val_acc: 0.8338\n",
            "Epoch 15/100\n",
            "50000/50000 [==============================] - 37s 740us/step - loss: 0.4240 - acc: 0.9093 - val_loss: 0.6334 - val_acc: 0.8366\n",
            "Epoch 16/100\n",
            "50000/50000 [==============================] - 37s 740us/step - loss: 0.4000 - acc: 0.9163 - val_loss: 0.6365 - val_acc: 0.8383\n",
            "Epoch 17/100\n",
            "50000/50000 [==============================] - 36s 723us/step - loss: 0.3804 - acc: 0.9204 - val_loss: 0.6445 - val_acc: 0.8320\n",
            "Epoch 18/100\n",
            "50000/50000 [==============================] - 37s 737us/step - loss: 0.3621 - acc: 0.9267 - val_loss: 0.6990 - val_acc: 0.8187\n",
            "Epoch 19/100\n",
            "50000/50000 [==============================] - 37s 738us/step - loss: 0.3470 - acc: 0.9294 - val_loss: 0.7168 - val_acc: 0.8167\n",
            "Epoch 20/100\n",
            "50000/50000 [==============================] - 37s 736us/step - loss: 0.3313 - acc: 0.9346 - val_loss: 0.7073 - val_acc: 0.8214\n",
            "Epoch 21/100\n",
            "50000/50000 [==============================] - 37s 735us/step - loss: 0.2717 - acc: 0.9598 - val_loss: 0.6075 - val_acc: 0.8467\n",
            "Epoch 22/100\n",
            "50000/50000 [==============================] - 38s 761us/step - loss: 0.2554 - acc: 0.9677 - val_loss: 0.6059 - val_acc: 0.8465\n",
            "Epoch 23/100\n",
            "50000/50000 [==============================] - 37s 737us/step - loss: 0.2482 - acc: 0.9702 - val_loss: 0.6101 - val_acc: 0.8459\n",
            "Epoch 24/100\n",
            "50000/50000 [==============================] - 37s 737us/step - loss: 0.2445 - acc: 0.9706 - val_loss: 0.6121 - val_acc: 0.8464\n",
            "Epoch 25/100\n",
            "50000/50000 [==============================] - 37s 731us/step - loss: 0.2368 - acc: 0.9730 - val_loss: 0.6122 - val_acc: 0.8490\n",
            "Epoch 26/100\n",
            "50000/50000 [==============================] - 37s 733us/step - loss: 0.2344 - acc: 0.9738 - val_loss: 0.6150 - val_acc: 0.8464\n",
            "Epoch 27/100\n",
            "50000/50000 [==============================] - 37s 734us/step - loss: 0.2288 - acc: 0.9757 - val_loss: 0.6185 - val_acc: 0.8443\n",
            "Epoch 28/100\n",
            "50000/50000 [==============================] - 37s 739us/step - loss: 0.2225 - acc: 0.9783 - val_loss: 0.6173 - val_acc: 0.8468\n",
            "Epoch 29/100\n",
            "50000/50000 [==============================] - 37s 739us/step - loss: 0.2213 - acc: 0.9791 - val_loss: 0.6177 - val_acc: 0.8460\n",
            "Epoch 30/100\n",
            "50000/50000 [==============================] - 37s 739us/step - loss: 0.2201 - acc: 0.9796 - val_loss: 0.6176 - val_acc: 0.8454\n",
            "Epoch 31/100\n",
            "50000/50000 [==============================] - 37s 734us/step - loss: 0.2197 - acc: 0.9788 - val_loss: 0.6170 - val_acc: 0.8458\n",
            "Epoch 32/100\n",
            "50000/50000 [==============================] - 37s 738us/step - loss: 0.2195 - acc: 0.9798 - val_loss: 0.6183 - val_acc: 0.8445\n",
            "Epoch 33/100\n",
            "50000/50000 [==============================] - 37s 737us/step - loss: 0.2183 - acc: 0.9798 - val_loss: 0.6178 - val_acc: 0.8459\n",
            "Epoch 34/100\n",
            "50000/50000 [==============================] - 36s 729us/step - loss: 0.2183 - acc: 0.9803 - val_loss: 0.6186 - val_acc: 0.8459\n",
            "Epoch 35/100\n",
            "50000/50000 [==============================] - 37s 739us/step - loss: 0.2192 - acc: 0.9795 - val_loss: 0.6183 - val_acc: 0.8462\n",
            "Epoch 36/100\n",
            "50000/50000 [==============================] - 37s 736us/step - loss: 0.2184 - acc: 0.9796 - val_loss: 0.6179 - val_acc: 0.8454\n",
            "Epoch 37/100\n",
            "50000/50000 [==============================] - 37s 738us/step - loss: 0.2177 - acc: 0.9806 - val_loss: 0.6180 - val_acc: 0.8463\n",
            "Epoch 38/100\n",
            "50000/50000 [==============================] - 37s 737us/step - loss: 0.2193 - acc: 0.9797 - val_loss: 0.6186 - val_acc: 0.8452\n",
            "Epoch 39/100\n",
            "50000/50000 [==============================] - 37s 738us/step - loss: 0.2182 - acc: 0.9794 - val_loss: 0.6182 - val_acc: 0.8456\n",
            "Epoch 40/100\n",
            "50000/50000 [==============================] - 37s 738us/step - loss: 0.2171 - acc: 0.9804 - val_loss: 0.6183 - val_acc: 0.8457\n",
            "Epoch 41/100\n",
            "50000/50000 [==============================] - 37s 736us/step - loss: 0.2172 - acc: 0.9806 - val_loss: 0.6177 - val_acc: 0.8463\n",
            "Epoch 42/100\n",
            "50000/50000 [==============================] - 36s 727us/step - loss: 0.2176 - acc: 0.9797 - val_loss: 0.6179 - val_acc: 0.8458\n",
            "Epoch 43/100\n",
            "50000/50000 [==============================] - 39s 788us/step - loss: 0.2175 - acc: 0.9799 - val_loss: 0.6187 - val_acc: 0.8456\n",
            "Epoch 44/100\n",
            "50000/50000 [==============================] - 37s 749us/step - loss: 0.2176 - acc: 0.9804 - val_loss: 0.6175 - val_acc: 0.8465\n",
            "Epoch 45/100\n",
            "50000/50000 [==============================] - 38s 752us/step - loss: 0.2168 - acc: 0.9804 - val_loss: 0.6182 - val_acc: 0.8464\n",
            "Epoch 46/100\n",
            "50000/50000 [==============================] - 39s 777us/step - loss: 0.2183 - acc: 0.9796 - val_loss: 0.6187 - val_acc: 0.8450\n",
            "Epoch 47/100\n",
            "50000/50000 [==============================] - 38s 752us/step - loss: 0.2181 - acc: 0.9804 - val_loss: 0.6190 - val_acc: 0.8462\n",
            "Epoch 48/100\n",
            "50000/50000 [==============================] - 38s 751us/step - loss: 0.2171 - acc: 0.9800 - val_loss: 0.6181 - val_acc: 0.8468\n",
            "Epoch 49/100\n",
            "50000/50000 [==============================] - 38s 753us/step - loss: 0.2179 - acc: 0.9798 - val_loss: 0.6183 - val_acc: 0.8453\n",
            "Epoch 50/100\n",
            "26368/50000 [==============>...............] - ETA: 16s - loss: 0.2193 - acc: 0.9791"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-3505e72d095f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     callbacks=[ReduceLROnPlateau(patience=5)])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "jFd3VeB4xWNW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "48cfa30f-b268-47a7-8880-748429b38f9d"
      },
      "cell_type": "code",
      "source": [
        "# lr = K.get_value(model.optimizer.lr)\n",
        "# K.set_value(model.optimizer.lr, lr*0.60)\n",
        "# print((lr, K.get_value(model.optimizer.lr)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2.0000001e-19, 1.2000001e-19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fGOR9QcK4Vwk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history.epoch, history.history['loss'], history.epoch, history.history['val_loss'])\n",
        "plt.legend(['Training Loss', 'Validation Loss'])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}